{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "San Juan\nmean:  34.18055555555556\nvar : 2640.0454396910277\n\nIquitos\nmean:  7.565384615384615\nvar : 115.89552393656439\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/ipykernel_launcher.py:47: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n/usr/local/lib/python2.7/dist-packages/ipykernel_launcher.py:48: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best alpha =  1e-08\nbest score =  22.080882352941178\nbest alpha =  1e-08\nbest score =  6.466666666666667\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "from __future__ import division\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "import statsmodels.api as sm\n",
    "\n",
    "from statsmodels.tools import eval_measures\n",
    "import statsmodels.formula.api as smf\n",
    "\n",
    "# load the provided data\n",
    "train_features = pd.read_csv('./input/dengue_features_train.csv',\n",
    "                             index_col=[0, 1, 2])\n",
    "\n",
    "train_labels = pd.read_csv('./input/dengue_labels_train.csv',\n",
    "                           index_col=[0, 1, 2])\n",
    "\n",
    "# Seperate data for San Juan\n",
    "sj_train_features = train_features.loc['sj']\n",
    "sj_train_labels = train_labels.loc['sj']\n",
    "\n",
    "# Separate data for Iquitos\n",
    "iq_train_features = train_features.loc['iq']\n",
    "iq_train_labels = train_labels.loc['iq']\n",
    "\n",
    "# remove null values \n",
    "sj_train_features.fillna(method='ffill', inplace=True)\n",
    "iq_train_features.fillna(method='ffill', inplace=True)\n",
    "\n",
    "# mean variance\n",
    "print('San Juan')\n",
    "print('mean: ', sj_train_labels.mean()[0])\n",
    "print('var :', sj_train_labels.var()[0])\n",
    "\n",
    "print('\\nIquitos')\n",
    "print('mean: ', iq_train_labels.mean()[0])\n",
    "print('var :', iq_train_labels.var()[0])\n",
    "\n",
    "sj_train_labels.hist()\n",
    "plt.show()\n",
    "\n",
    "sj_train_features['total_cases'] = sj_train_labels.total_cases\n",
    "iq_train_features['total_cases'] = iq_train_labels.total_cases\n",
    "\n",
    "# compute the correlations\n",
    "sj_correlations = sj_train_features.corr()\n",
    "iq_correlations = iq_train_features.corr()\n",
    "\n",
    "# plot san juan\n",
    "sj_corr_heat = sns.heatmap(sj_correlations)\n",
    "plt.title('San Juan Variable Correlations')\n",
    "plt.show()\n",
    "\n",
    "# plot iquitos\n",
    "iq_corr_heat = sns.heatmap(iq_correlations)\n",
    "plt.title('Iquitos Variable Correlations')\n",
    "plt.show()\n",
    "\n",
    "# San Juan\n",
    "(sj_correlations\n",
    " .total_cases\n",
    " .drop('total_cases')  # don't compare with myself\n",
    " .sort_values(ascending=False)\n",
    " .plot\n",
    " .barh())\n",
    "plt.show()\n",
    "\n",
    "# Iquitos\n",
    "(iq_correlations\n",
    " .total_cases\n",
    " .drop('total_cases')  # don't compare with myself\n",
    " .sort_values(ascending=False)\n",
    " .plot\n",
    " .barh())\n",
    "\n",
    "\n",
    "def preprocess_data(data_path, labels_path=None):\n",
    "    # load data and set index to city, year, weekofyear\n",
    "    df = pd.read_csv(data_path, index_col=[0, 1, 2])\n",
    "\n",
    "    # select features we want\n",
    "    features = ['reanalysis_specific_humidity_g_per_kg',\n",
    "                'reanalysis_dew_point_temp_k',\n",
    "                'station_avg_temp_c',\n",
    "                'station_min_temp_c']\n",
    "    df = df[features]\n",
    "\n",
    "    # fill missing values\n",
    "    df.fillna(method='ffill', inplace=True)\n",
    "\n",
    "    # add labels to dataframe\n",
    "    if labels_path:\n",
    "        labels = pd.read_csv(labels_path, index_col=[0, 1, 2])\n",
    "        df = df.join(labels)\n",
    "\n",
    "    # separate san juan and iquitos\n",
    "    sj = df.loc['sj']\n",
    "    iq = df.loc['iq']\n",
    "\n",
    "    return sj, iq\n",
    "\n",
    "\n",
    "sj_train, iq_train = preprocess_data('./input/dengue_features_train.csv', labels_path=\"./input/dengue_labels_train.csv\")\n",
    "sj_train.describe()\n",
    "iq_train.describe()\n",
    "\n",
    "sj_train_subtrain = sj_train.head(800)\n",
    "sj_train_subtest = sj_train.tail(sj_train.shape[0] - 800)\n",
    "\n",
    "iq_train_subtrain = iq_train.head(400)\n",
    "iq_train_subtest = iq_train.tail(iq_train.shape[0] - 400)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def get_best_model(train, test):\n",
    "    # Step 1: specify the form of the model\n",
    "    model_formula = \"total_cases ~ 1 + \" \\\n",
    "                    \"reanalysis_specific_humidity_g_per_kg + \" \\\n",
    "                    \"reanalysis_dew_point_temp_k + \" \\\n",
    "                    \"station_min_temp_c + \" \\\n",
    "                    \"station_avg_temp_c\"\n",
    "    \n",
    "    grid = 10 ** np.arange(-8, -3, dtype=np.float64)\n",
    "                    \n",
    "    best_alpha = []\n",
    "    best_score = 1000\n",
    "        \n",
    "    # Step 2: Find the best hyper parameter, alpha\n",
    "    for alpha in grid:\n",
    "        model = smf.glm(formula=model_formula,\n",
    "                        data=train,\n",
    "                        family=sm.families.NegativeBinomial(alpha=alpha))\n",
    "\n",
    "        results = model.fit()\n",
    "        predictions = results.predict(test).astype(int)\n",
    "        score = eval_measures.meanabs(predictions, test.total_cases)\n",
    "\n",
    "        if score < best_score:\n",
    "            best_alpha = alpha\n",
    "            best_score = score\n",
    "\n",
    "    print('best alpha = ', best_alpha)\n",
    "    print('best score = ', best_score)\n",
    "            \n",
    "    # Step 3: refit on entire dataset\n",
    "    full_dataset = pd.concat([train, test])\n",
    "    model = smf.glm(formula=model_formula,\n",
    "                    data=full_dataset,\n",
    "                    family=sm.families.NegativeBinomial(alpha=best_alpha))\n",
    "\n",
    "    fitted_model = model.fit()\n",
    "    return fitted_model\n",
    "  \n",
    "    \n",
    "sj_best_model = get_best_model(sj_train_subtrain, sj_train_subtest)\n",
    "iq_best_model = get_best_model(iq_train_subtrain, iq_train_subtest)\n",
    "\n",
    "figs, axes = plt.subplots(nrows=2, ncols=1)\n",
    "\n",
    "# plot sj\n",
    "sj_train['fitted'] = sj_best_model.fittedvalues\n",
    "sj_train.fitted.plot(ax=axes[0], label=\"Predictions\")\n",
    "sj_train.total_cases.plot(ax=axes[0], label=\"Actual\")\n",
    "\n",
    "# plot iq\n",
    "iq_train['fitted'] = iq_best_model.fittedvalues\n",
    "iq_train.fitted.plot(ax=axes[1], label=\"Predictions\")\n",
    "iq_train.total_cases.plot(ax=axes[1], label=\"Actual\")\n",
    "\n",
    "plt.suptitle(\"Dengue Predicted Cases vs. Actual Cases\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "plt.show()\n",
    "\n",
    "sj_test, iq_test = preprocess_data('./input/dengue_features_test.csv')\n",
    "\n",
    "sj_predictions = sj_best_model.predict(sj_test).astype(int)\n",
    "iq_predictions = iq_best_model.predict(iq_test).astype(int)\n",
    "\n",
    "submission = pd.read_csv(\"./input/submission_format.csv\",\n",
    "                         index_col=[0, 1, 2])\n",
    "\n",
    "submission.total_cases = np.concatenate([sj_predictions, iq_predictions])\n",
    "submission.to_csv(\"./input/benchmark.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
